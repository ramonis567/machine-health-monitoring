{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"DURFi7PxQy5jY2CJSseIpn7VDlrk-TEYbh5bWWguQeWIrn-PjfZo6nde4DQ_pm-sUDI5GCMvypkHvAR0e9JVOw=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import paho.mqtt.client as paho\n",
    "from paho import mqtt\n",
    "from influxdb_client_3 import InfluxDBClient3, Point\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "\n",
    "# Carregar configurações do arquivo config.json\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "machine_id = config[\"machine_id\"]\n",
    "sensors = config[\"sensors\"]\n",
    "\n",
    "# Configurações do InfluxDB\n",
    "influx_token = \"DURFi7PxQy5jY2CJSseIpn7VDlrk-TEYbh5bWWguQeWIrn-PjfZo6nde4DQ_pm-sUDI5GCMvypkHvAR0e9JVOw==\"\n",
    "influx_org = \"EngContrAut\"\n",
    "influx_host = \"https://us-east-1-1.aws.cloud2.influxdata.com\"\n",
    "client_DB = InfluxDBClient3(host=influx_host, token=influx_token, org=influx_org)\n",
    "\n",
    "# Configurações do MQTT\n",
    "mqtt_config = config[\"mqtt\"]\n",
    "mqtt_broker = mqtt_config[\"broker_url\"]\n",
    "mqtt_port = mqtt_config[\"broker_port\"]\n",
    "mqtt_username = mqtt_config[\"username\"]\n",
    "mqtt_password = mqtt_config[\"password\"]\n",
    "\n",
    "# Dicionário para armazenar o último timestamp de cada sensor e o data_interval\n",
    "last_seen = {}\n",
    "data_intervals = {}\n",
    "\n",
    "# Callback para processar mensagens MQTT\n",
    "def on_message(client, userdata, message):\n",
    "    topic = message.topic\n",
    "    payload = json.loads(message.payload.decode())\n",
    "    \n",
    "    # print(f\"Received message: {topic} -> {json.dumps(payload, indent=2)}\")\n",
    "\n",
    "    handle_sensor_data(topic, payload)\n",
    "\n",
    "def handle_sensor_data(topic, data):\n",
    "    machine_id, sensor_id = parse_topic(topic)\n",
    "    timestamp = datetime.strptime(data[\"timestamp\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    value = data[\"value\"]\n",
    "    \n",
    "    print(f\"Data: {machine_id} - Sensor {sensor_id} at {timestamp}: value={value}\")\n",
    "    \n",
    "    data_to_db(machine_id, sensor_id, timestamp, value)\n",
    "    check_inactivity(machine_id, sensor_id, timestamp)\n",
    "    custom_processing(machine_id, sensor_id, timestamp, value)\n",
    "\n",
    "def data_to_db(machine_id, sensor_id, timestamp, value):\n",
    "    point = Point(sensor_id).tag(\"machine_id\", machine_id).field(\"value\", value).time(timestamp)\n",
    "    # print(f\"Saving data to InfluxDB bucket {sensor_id}_data for {machine_id} - {sensor_id} at {timestamp}: value={value}\")\n",
    "\n",
    "    try:\n",
    "        client_DB.write(database=f\"{sensor_id}_data\", record=point)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write to InfluxDB: {e}\")\n",
    "\n",
    "def check_inactivity(machine_id, sensor_id, timestamp):\n",
    "    data_interval = data_intervals.get((machine_id, sensor_id), 5)  # Usar 5 segundos como padrão se não encontrado\n",
    "    inactive_threshold = timedelta(seconds=10 * data_interval)  # 10 períodos de tempo previstos\n",
    "\n",
    "    if (machine_id, sensor_id) in last_seen:\n",
    "        last_seen_time = last_seen[(machine_id, sensor_id)]\n",
    "        if timestamp - last_seen_time > inactive_threshold:\n",
    "            print(f\"Inactive alarm triggered for {machine_id}/{sensor_id}\")\n",
    "            raise_alarm(machine_id, \"inactive\")\n",
    "    last_seen[(machine_id, sensor_id)] = timestamp\n",
    "\n",
    "def custom_processing(machine_id, sensor_id, timestamp, value):\n",
    "    # if (machine_id, sensor_id) not in sensor_data_queues:\n",
    "    #     sensor_data_queues[(machine_id, sensor_id)] = deque(maxlen=5)\n",
    "    \n",
    "    # sensor_data_queues[(machine_id, sensor_id)].append(value)\n",
    "    # moving_average = sum(sensor_data_queues[(machine_id, sensor_id)]) / len(sensor_data_queues[(machine_id, sensor_id)])\n",
    "    \n",
    "    # print(f\"Custom processing for {machine_id}/{sensor_id} at {timestamp}: value={value}, moving average={moving_average}\")\n",
    "    \n",
    "    # point = Point(f\"{sensor_id}_moving_average\").tag(\"machine_id\", machine_id).field(\"value\", moving_average).time(timestamp)\n",
    "    # bucket = f\"{sensor_id}_med_movel\"\n",
    "    # try:\n",
    "    #     client_DB.write(database=bucket, record=point)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Failed to write moving average to InfluxDB: {e}\")\n",
    "    pass\n",
    "\n",
    "def raise_alarm(machine_id, alarm_type):\n",
    "#     point = Point(alarm_type).tag(\"machine_id\", machine_id).field(\"value\", 1).time(datetime.utcnow())\n",
    "#     bucket = f\"{machine_id}_alarms\"\n",
    "#     print(f\"Raising alarm for {machine_id}: {alarm_type}\")\n",
    "#     try:\n",
    "#         client_DB.write(database=bucket, record=point)\n",
    "#     except Exception as e:\n",
    "#         log(f\"Failed to raise alarm: {e}\")\n",
    "    pass\n",
    "\n",
    "def parse_topic(topic):\n",
    "    parts = topic.split('/')\n",
    "    return parts[2], parts[3]\n",
    "\n",
    "# Função para subscrever a um tópico específico em uma thread separada\n",
    "def subscribe_to_topic(topic):\n",
    "    client = paho.Client(client_id=\"\", userdata=None, protocol=paho.MQTTv5)\n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "\n",
    "    client.tls_set(tls_version=mqtt.client.ssl.PROTOCOL_TLS)\n",
    "    client.username_pw_set(mqtt_username, mqtt_password)\n",
    "    client.connect(mqtt_broker, mqtt_port)\n",
    "\n",
    "    client.subscribe(topic)\n",
    "    client.loop_forever()\n",
    "\n",
    "def on_connect(client, userdata, flags, rc, properties=None):\n",
    "    print(f\"CONNACK received with code {rc}\")\n",
    "\n",
    "# Criar e iniciar uma thread para cada tópico de sensor\n",
    "for sensor in sensors:\n",
    "    sensor_id = sensor[\"sensor_id\"]\n",
    "    data_interval = sensor[\"data_interval\"]\n",
    "    topic = f\"/sensors/{machine_id}/{sensor_id}\"\n",
    "\n",
    "    # Armazenar o data_interval para calcular o inactive_threshold dinamicamente\n",
    "    data_intervals[(machine_id, sensor_id)] = data_interval / 1000  # Converter para segundos\n",
    "\n",
    "    thread = threading.Thread(target=subscribe_to_topic, args=(topic,))\n",
    "    thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
